{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b13b23-553b-4ced-8cd8-37d7a7965802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import cfg\n",
    "from datetime import datetime\n",
    "\n",
    "from torchvision.utils import save_image, make_grid\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from types import SimpleNamespace\n",
    "import json\n",
    "\n",
    "from models.ResNet import Res12_Quadratic, Res18_Quadratic, Res34_Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e780d61-3b26-44b5-bcd0-afbe43fcade2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = SimpleNamespace()\n",
    "args.n_iter = 25000\n",
    "args.num_sub = 50 # number of subjects per contrast\n",
    "args.res = 64\n",
    "args.classes = [0]\n",
    "args.batch_size = 128\n",
    "args.in_chan = 1\n",
    "args.n_chan = 128\n",
    "args.n_gpus = 1\n",
    "args.max_lr = 1e-5\n",
    "args.min_noise = 0.1\n",
    "args.max_noise = 3.0\n",
    "args.noise_distribution = 'exp'\n",
    "args.save_every = 1000\n",
    "args.dataset = 'fastmri'\n",
    "args.log = 'fastmri_EBM'\n",
    "\n",
    "# resume from previous checkpoint\n",
    "args.cont = False \n",
    "# timestamp to resume training\n",
    "# args.time = '2024_May15_08_38'\n",
    "args.time = ''\n",
    "args.net_indx = 100000\n",
    "\n",
    "args.lr_schedule = 'cosine'\n",
    "args.rand_seed = 42\n",
    "args.file_name = 'mdsm_ebm'\n",
    "args.net = 'res34'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266331d3-52e2-4543-99f7-d903d42229ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.manual_seed(args.rand_seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# DATA LOADER\n",
    "from data.fastmri_brain import inf_train_gen, inf_train_gen_downsampled\n",
    "# itr = inf_train_gen(args.batch_size, num_sub=args.num_sub)\n",
    "itr = inf_train_gen_downsampled(args.batch_size, num_sub=args.num_sub, device=device, res=args.res, complex_in=False, classes=args.classes)\n",
    "\n",
    "if args.net == 'res18':\n",
    "    netE = Res18_Quadratic(args.in_chan,args.n_chan,32,normalize=False,AF=nn.ELU())\n",
    "elif args.net == 'res34':\n",
    "    netE = Res34_Quadratic(args.in_chan,args.n_chan,32,normalize=False,AF=nn.ELU())\n",
    "\n",
    "netE = netE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ffc11f-b7a0-4119-a68a-01ebb4c74944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAIR_big_pickle - loading 50 of 108 subjects\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1.0000, dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "min/max: tensor(0., dtype=torch.float64) / tensor(1., dtype=torch.float64)\n",
      "ksp: torch.Size([10, 12, 320, 320]) \tcsm: torch.Size([10, 12, 320, 320])\n",
      "Loaded dataset of 500 slices\n",
      "\n",
      "Resizing to 64x64\n",
      "Resized org: torch.Size([500, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x_real = itr.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a5667b-6e01-49d5-a3fb-c45194f83cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365cb3d5-87d5-4b96-a4a3-b3b977f90f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Preloading from  logs/fastmri_EBM_2024_May29_16_13/models/mdsm_ebm100000.pt\n",
      "Preloading successful \n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "timestamp = now.strftime('%Y_%b%d_%H_%M')\n",
    "print(str(args.cont))\n",
    "# print(str(args.time))\n",
    "if args.cont==True:\n",
    "    root = 'logs/' + args.log + '_'+ args.time #compose string for loading\n",
    "    #load network\n",
    "    file_name = args.file_name + str(args.net_indx) + '.pt'\n",
    "    print(\"Preloading from \",root+ '/models/' +file_name)\n",
    "    netE.load_state_dict(torch.load(root + '/models/' +file_name))\n",
    "    print(\"Preloading successful \")\n",
    "else: # start new will create logging folder\n",
    "    root = 'logs/'+ args.log + '_' + timestamp #add timestemp\n",
    "    #over write if folder already exist, not likely to happen as timestamp is used\n",
    "    if os.path.isdir(root):\n",
    "        shutil.rmtree(root)\n",
    "    os.makedirs(root)\n",
    "    os.makedirs(root+'/models')\n",
    "    os.makedirs(root+'/samples')\n",
    "\n",
    "log_fname = root + \"/log.txt\"\n",
    "def print_log(string, mute=False):\n",
    "    with open(log_fname, \"a\", encoding='utf8') as log: # append mode \n",
    "        log.write(string+\"\\n\")\n",
    "    if not mute: print(string)\n",
    "    \n",
    "settings_fname = root + f\"/settings_{timestamp}.json\"\n",
    "with open(settings_fname, \"w\", encoding='utf8') as sf:\n",
    "    json.dump(args.__dict__, sf, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bab5a9-fc30-4823-8a08-6f08180ab747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started -- logs/fastmri_EBM_2024_May29_16_13\n",
      "Iteration 100250/125000 (80%), E_real -8.387317e+04, E_noise -7.389418e+04, Normalized Loss 8.024816e+00, time 308.8\n",
      "Iteration 100500/125000 (80%), E_real -8.281145e+04, E_noise -7.282845e+04, Normalized Loss 7.606600e+00, time 308.7\n",
      "Iteration 100750/125000 (81%), E_real -8.196445e+04, E_noise -7.203902e+04, Normalized Loss 8.008731e+00, time 308.7\n",
      "Iteration 101000/125000 (81%), E_real -8.116862e+04, E_noise -7.104477e+04, Normalized Loss 7.690745e+00, time 308.7\n",
      "--------------------------------------------------\n",
      "Iteration 101250/125000 (81%), E_real -8.069720e+04, E_noise -7.068544e+04, Normalized Loss 8.024630e+00, time 313.6\n",
      "Iteration 101500/125000 (81%), E_real -8.008139e+04, E_noise -7.016610e+04, Normalized Loss 7.410288e+00, time 308.7\n",
      "Iteration 101750/125000 (81%), E_real -7.981743e+04, E_noise -6.987573e+04, Normalized Loss 8.181366e+00, time 308.7\n",
      "Iteration 102000/125000 (82%), E_real -7.916834e+04, E_noise -6.924633e+04, Normalized Loss 8.434402e+00, time 308.7\n",
      "--------------------------------------------------\n",
      "Iteration 102250/125000 (82%), E_real -7.886423e+04, E_noise -6.905839e+04, Normalized Loss 7.513977e+00, time 315.5\n",
      "Iteration 102500/125000 (82%), E_real -7.841747e+04, E_noise -6.847673e+04, Normalized Loss 7.606423e+00, time 308.7\n",
      "Iteration 102750/125000 (82%), E_real -7.796062e+04, E_noise -6.805134e+04, Normalized Loss 8.298788e+00, time 308.7\n",
      "Iteration 103000/125000 (82%), E_real -7.795284e+04, E_noise -6.788441e+04, Normalized Loss 7.338130e+00, time 308.7\n",
      "--------------------------------------------------\n",
      "Iteration 103250/125000 (83%), E_real -7.764162e+04, E_noise -6.775148e+04, Normalized Loss 7.667430e+00, time 313.4\n",
      "Iteration 103500/125000 (83%), E_real -7.754796e+04, E_noise -6.757446e+04, Normalized Loss 7.876141e+00, time 308.7\n",
      "Iteration 103750/125000 (83%), E_real -7.715600e+04, E_noise -6.712945e+04, Normalized Loss 7.927341e+00, time 308.7\n",
      "Iteration 104000/125000 (83%), E_real -7.685078e+04, E_noise -6.699405e+04, Normalized Loss 7.694368e+00, time 308.7\n",
      "--------------------------------------------------\n",
      "Iteration 104250/125000 (83%), E_real -7.675435e+04, E_noise -6.677975e+04, Normalized Loss 7.604021e+00, time 314.6\n",
      "Iteration 104500/125000 (84%), E_real -7.639373e+04, E_noise -6.645427e+04, Normalized Loss 7.080405e+00, time 308.7\n",
      "Iteration 104750/125000 (84%), E_real -7.614153e+04, E_noise -6.630109e+04, Normalized Loss 7.303875e+00, time 308.7\n",
      "Iteration 105000/125000 (84%), E_real -7.607724e+04, E_noise -6.615981e+04, Normalized Loss 7.109461e+00, time 308.7\n",
      "--------------------------------------------------\n",
      "Iteration 105250/125000 (84%), E_real -7.578947e+04, E_noise -6.591203e+04, Normalized Loss 7.344455e+00, time 314.2\n",
      "Iteration 105500/125000 (84%), E_real -7.535692e+04, E_noise -6.541116e+04, Normalized Loss 7.130663e+00, time 308.7\n"
     ]
    }
   ],
   "source": [
    "# writer = SummaryWriter(root)\n",
    "\n",
    "# setup optimizer and lr scheduler\n",
    "params = {'lr':args.max_lr,'betas':(0.9,0.95)}\n",
    "optimizerE = torch.optim.Adam(netE.parameters(),**params)\n",
    "if args.lr_schedule == 'exp':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizerE,int(args.n_iter/6))\n",
    "\n",
    "elif args.lr_schedule == 'cosine':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizerE,args.n_iter,eta_min=1e-6,last_epoch=-1)\n",
    "\n",
    "elif args.lr_schedule == 'const':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizerE,int(args.n_iter))\n",
    "\n",
    "#train\n",
    "print_interval = args.save_every // 4\n",
    "max_iter = args.n_iter+args.net_indx\n",
    "batchSize = args.batch_size\n",
    "sigma0 = 0.1\n",
    "sigma02 = sigma0**2\n",
    "\n",
    "if args.noise_distribution == 'exp':\n",
    "    sigmas_np = np.logspace(np.log10(args.min_noise),np.log10(args.max_noise),batchSize)\n",
    "elif args.noise_distribution == 'lin':\n",
    "    sigmas_np = np.linspace(args.min_noise,args.max_noise,batchSize)\n",
    "\n",
    "sigmas = torch.Tensor(sigmas_np).view((batchSize,1,1,1)).to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print_log(f'Training started -- {root}')\n",
    "for i in range(args.net_indx,args.net_indx + args.n_iter):\n",
    "    x_real = itr.__next__().to(device)\n",
    "    x_noisy = x_real + sigmas*torch.randn_like(x_real)\n",
    "\n",
    "    x_noisy = x_noisy.requires_grad_()\n",
    "    E = netE(x_noisy).sum()\n",
    "    grad_x = torch.autograd.grad(E,x_noisy,create_graph=True)[0]\n",
    "    x_noisy.detach()\n",
    "\n",
    "    optimizerE.zero_grad()\n",
    "\n",
    "    LS_loss = ((((x_real-x_noisy)/sigmas/sigma02+grad_x/sigmas)**2)/batchSize).sum()\n",
    "\n",
    "    LS_loss.backward()\n",
    "    optimizerE.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if (i+1)%print_interval == 0:\n",
    "        time_spent = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        netE.eval()\n",
    "        E_real = netE(x_real).mean()\n",
    "        E_noise = netE(torch.rand_like(x_real)).mean()\n",
    "        netE.train()\n",
    "\n",
    "        print_log('Iteration {}/{} ({:.0f}%), E_real {:e}, E_noise {:e}, Normalized Loss {:e}, time {:4.1f}'.format(i+1,max_iter,100*((i+1)/max_iter),E_real.item(),E_noise.item(),(sigma02**2)*(LS_loss.item()),time_spent))\n",
    "\n",
    "        # writer.add_scalar('E_real',E_real.item(),i+1)\n",
    "        # writer.add_scalar('E_noise',E_noise.item(),i+1)\n",
    "        # writer.add_scalar('loss',(sigma02**2)*LS_loss.item(),i+1)\n",
    "        del E_real, E_noise, x_real, x_noisy\n",
    "\n",
    "    if (i+1)%args.save_every == 0:\n",
    "        print_log(\"-\"*50)\n",
    "        file_name = args.file_name+str(i+1)+'.pt'\n",
    "        torch.save(netE.state_dict(),root+'/models/'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd74be-f262-4a5b-b88f-b73cea54f7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
