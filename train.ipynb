{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b13b23-553b-4ced-8cd8-37d7a7965802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import cfg\n",
    "from datetime import datetime\n",
    "\n",
    "from torchvision.utils import save_image, make_grid\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from models.ResNet import Res12_Quadratic, Res18_Quadratic, Res34_Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7579dd1b-3250-4f18-b766-5b719bb1cc8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = SimpleNamespace()\n",
    "args.n_iter = 1000\n",
    "args.batch_size = 256\n",
    "args.n_chan = 64\n",
    "args.n_gpus = 1\n",
    "args.max_lr = 1e-4\n",
    "args.min_noise = 0.1\n",
    "args.max_noise = 3\n",
    "args.noise_distribution = 'exp'\n",
    "args.save_every = 500\n",
    "args.dataset = 'fmnist'\n",
    "args.cont = True\n",
    "args.log = 'fmnist_EBM'\n",
    "args.time = '2024_Apr28_12_10' # timestamp to resume training\n",
    "args.lr_schedule = 'cosine'\n",
    "args.rand_seed = 42\n",
    "args.net_indx = 1000\n",
    "args.file_name = 'mdsm_ebm'\n",
    "\n",
    "# args = SimpleNamespace()\n",
    "# args.n_iter = 10000\n",
    "# args.batch_size = 128\n",
    "# args.n_chan = 128\n",
    "# args.n_gpus = 1\n",
    "# args.max_lr = 5e-5\n",
    "# args.min_noise = 0.05\n",
    "# args.max_noise = 1.2\n",
    "# args.noise_distribution = 'lin'\n",
    "# args.save_every = 5000\n",
    "# args.dataset = 'celeba'\n",
    "# args.log = 'celeba_EBM'\n",
    "# args.lr_schedule = 'cosine'\n",
    "# args.rand_seed = 42\n",
    "# args.cont = False\n",
    "# args.net_indx = 0\n",
    "# args.file_name = 'mdsm_ebm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266331d3-52e2-4543-99f7-d903d42229ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.manual_seed(args.rand_seed)\n",
    "\n",
    "if args.dataset == 'cifar':\n",
    "    from data.cifar import inf_train_gen\n",
    "    itr = inf_train_gen(args.batch_size,flip=False)\n",
    "    netE = Res18_Quadratic(3,args.n_chan,32,normalize=False,AF=nn.ELU())\n",
    "    \n",
    "elif args.dataset == 'mnist':\n",
    "    from data.mnist_32 import inf_train_gen\n",
    "    itr = inf_train_gen(args.batch_size)\n",
    "    netE = Res12_Quadratic(1,args.n_chan,32,normalize=False,AF=nn.ELU())\n",
    "    \n",
    "elif args.dataset == 'fmnist':\n",
    "    #print(dataset+str(args.n_chan))\n",
    "    from data.fashion_mnist_32 import inf_train_gen\n",
    "    itr = inf_train_gen(args.batch_size)\n",
    "    netE = Res12_Quadratic(1,args.n_chan,32,normalize=False,AF=nn.ELU())\n",
    "    \n",
    "elif args.dataset == 'celeba':\n",
    "    #print(dataset+str(args.n_chan))\n",
    "    from data.celeba import inf_train_gen\n",
    "    itr = inf_train_gen(args.batch_size)\n",
    "    netE = Res18_Quadratic(3,args.n_chan,32,normalize=False,AF=nn.ELU())\n",
    "\n",
    "else:\n",
    "    NotImplementedError('{} unknown dataset'.format(args.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d35ad71-24f3-4d3e-83b3-5b1c48376d67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "netE = netE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "365cb3d5-87d5-4b96-a4a3-b3b977f90f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Preloading from  logs/fmnist_EBM_2024_Apr28_12_10/models/mdsm_ebm1000.pt\n",
      "Preloading successful \n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "timestamp = now.strftime('%Y_%b%d_%H_%M')\n",
    "print(str(args.cont))\n",
    "# print(str(args.time))\n",
    "if args.cont==True:\n",
    "    root = 'logs/' + args.log + '_'+ args.time #compose string for loading\n",
    "    #load network\n",
    "    file_name = args.file_name + str(args.net_indx) + '.pt'\n",
    "    print(\"Preloading from \",root+ '/models/' +file_name)\n",
    "    netE.load_state_dict(torch.load(root + '/models/' +file_name))\n",
    "    print(\"Preloading successful \")\n",
    "else: # start new will create logging folder\n",
    "    root = 'logs/'+ args.log + '_' + timestamp #add timestemp\n",
    "    #over write if folder already exist, not likely to happen as timestamp is used\n",
    "    if os.path.isdir(root):\n",
    "        shutil.rmtree(root)\n",
    "    os.makedirs(root)\n",
    "    os.makedirs(root+'/models')\n",
    "    os.makedirs(root+'/samples')\n",
    "\n",
    "log_fname = root + \"/log.txt\"\n",
    "def print_log(string, mute=False):\n",
    "    with open(log_fname, \"a\", encoding='utf8') as log: # append mode \n",
    "        log.write(string+\"\\n\")\n",
    "    if not mute: print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39bab5a9-fc30-4823-8a08-6f08180ab747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Iteration 1125/2000 (56%), E_real -3.851346e+05, E_noise -3.820644e+05, Normalized Loss 3.239212e+02, time 20.8\n",
      "Iteration 1250/2000 (62%), E_real -7.013970e+05, E_noise -6.975259e+05, Normalized Loss 1.382604e+02, time 19.2\n",
      "Iteration 1375/2000 (69%), E_real -7.155488e+05, E_noise -7.107834e+05, Normalized Loss 1.162074e+02, time 19.0\n",
      "Iteration 1500/2000 (75%), E_real -7.408106e+05, E_noise -7.355999e+05, Normalized Loss 1.071651e+02, time 19.3\n",
      "--------------------------------------------------\n",
      "Iteration 1625/2000 (81%), E_real -7.759752e+05, E_noise -7.707541e+05, Normalized Loss 1.016989e+02, time 19.2\n",
      "Iteration 1750/2000 (88%), E_real -8.069706e+05, E_noise -8.018905e+05, Normalized Loss 9.919466e+01, time 19.3\n",
      "Iteration 1875/2000 (94%), E_real -8.315058e+05, E_noise -8.260849e+05, Normalized Loss 9.319047e+01, time 19.0\n",
      "Iteration 2000/2000 (100%), E_real -8.403926e+05, E_noise -8.349966e+05, Normalized Loss 9.585524e+01, time 19.3\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# writer = SummaryWriter(root)\n",
    "\n",
    "# setup optimizer and lr scheduler\n",
    "params = {'lr':args.max_lr,'betas':(0.9,0.95)}\n",
    "optimizerE = torch.optim.Adam(netE.parameters(),**params)\n",
    "if args.lr_schedule == 'exp':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizerE,int(args.n_iter/6))\n",
    "\n",
    "elif args.lr_schedule == 'cosine':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizerE,args.n_iter,eta_min=1e-6,last_epoch=-1)\n",
    "\n",
    "elif args.lr_schedule == 'const':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizerE,int(args.n_iter))\n",
    "\n",
    "#train\n",
    "print_interval = args.save_every // 4\n",
    "max_iter = args.n_iter+args.net_indx\n",
    "batchSize = args.batch_size\n",
    "sigma0 = 0.1\n",
    "sigma02 = sigma0**2\n",
    "\n",
    "if args.noise_distribution == 'exp':\n",
    "    sigmas_np = np.logspace(np.log10(args.min_noise),np.log10(args.max_noise),batchSize)\n",
    "elif args.noise_distribution == 'lin':\n",
    "    sigmas_np = np.linspace(args.min_noise,args.max_noise,batchSize)\n",
    "\n",
    "sigmas = torch.Tensor(sigmas_np).view((batchSize,1,1,1)).to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print_log('Training started')\n",
    "for i in range(args.net_indx,args.net_indx + args.n_iter):\n",
    "    x_real = itr.__next__().to(device)\n",
    "    x_noisy = x_real + sigmas*torch.randn_like(x_real)\n",
    "\n",
    "    x_noisy = x_noisy.requires_grad_()\n",
    "    E = netE(x_noisy).sum()\n",
    "    grad_x = torch.autograd.grad(E,x_noisy,create_graph=True)[0]\n",
    "    x_noisy.detach()\n",
    "\n",
    "    optimizerE.zero_grad()\n",
    "\n",
    "    LS_loss = ((((x_real-x_noisy)/sigmas/sigma02+grad_x/sigmas)**2)/batchSize).sum()\n",
    "\n",
    "    LS_loss.backward()\n",
    "    optimizerE.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if (i+1)%print_interval == 0:\n",
    "        time_spent = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        netE.eval()\n",
    "        E_real = netE(x_real).mean()\n",
    "        E_noise = netE(torch.rand_like(x_real)).mean()\n",
    "        netE.train()\n",
    "\n",
    "        print_log('Iteration {}/{} ({:.0f}%), E_real {:e}, E_noise {:e}, Normalized Loss {:e}, time {:4.1f}'.format(i+1,max_iter,100*((i+1)/max_iter),E_real.item(),E_noise.item(),(sigma02**2)*(LS_loss.item()),time_spent))\n",
    "\n",
    "        # writer.add_scalar('E_real',E_real.item(),i+1)\n",
    "        # writer.add_scalar('E_noise',E_noise.item(),i+1)\n",
    "        # writer.add_scalar('loss',(sigma02**2)*LS_loss.item(),i+1)\n",
    "        del E_real, E_noise, x_real, x_noisy\n",
    "\n",
    "    if (i+1)%args.save_every == 0:\n",
    "        print_log(\"-\"*50)\n",
    "        file_name = args.file_name+str(i+1)+'.pt'\n",
    "        torch.save(netE.state_dict(),root+'/models/'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd74be-f262-4a5b-b88f-b73cea54f7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
